{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from html import unescape\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()\n",
    "ua = UserAgent(verify_ssl=False)  # ради безопасности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsedate(date):\n",
    "    url = f'https://lenta.ru{date}'\n",
    "    response = session.get(url, headers={'User-Agent': ua.random})\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    main = soup.find('section', {'class':'b-layout js-layout b-layout_archive'})\n",
    "    next_l = main.find_all('a', {'class':'control_mini'})[1].get('href')\n",
    "    \n",
    "    news = main.find_all('div', {'class':'titles'})\n",
    "    links = [newss.find('a').get('href') for newss in news]\n",
    "    links = [link for link in links if link.startswith('/news')]\n",
    "            \n",
    "    return links, next_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsenews(links, date):\n",
    "    wholeday = ''\n",
    "\n",
    "    for link in tqdm(links):\n",
    "        url = f'https://lenta.ru{link}'\n",
    "        response = session.get(url, headers={'User-Agent': ua.random})\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        headline = soup.find('h1', {'itemprop':'headline'}).get_text()\n",
    "        text = soup.find('div', {'itemprop':'articleBody'})\n",
    "        passages = text.find_all('p')\n",
    "        passages = [p.get_text() for p in passages]\n",
    "        topic = soup.find('div', {'class':'b-topic__info'})\n",
    "        gmtime = topic.find('time').get_text().split(',')[0]\n",
    "        link_n = link.rsplit('/', 2)[1]\n",
    "        time_n = gmtime.strip(' ')\n",
    "        text_n = ' '.join(passages)\n",
    "        wholenews = f'<news>\\n<id>{link_n}</id>\\n<time>{time_n}</time>\\n<headline>{headline}</headline>\\n<text>{text_n}</text>\\n</news>\\n'\n",
    "        wholeday = wholeday + wholenews\n",
    "        time.sleep(random.uniform(1.5, 2.2))\n",
    "    \n",
    "    filename = 'l-' + date.strip('/').replace('/', '-') + '.txt'\n",
    "    \n",
    "    with open(filename, 'a+', encoding='utf-8') as f:\n",
    "        f.write(wholeday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(date):\n",
    "    links, next_date = parsedate(date)\n",
    "    createtxt = parsenews(links, date)\n",
    "    return next_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde61a163ca344cc899decfff93304e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314a448ae96547798b06d4a1fb4d5f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5ed9375d664523bfbd114127199d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83af4aa06fef4f0196c98ad088997722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "next_date = '/2002/01/01/'\n",
    "for i in range(4):\n",
    "    next_date = get_news(next_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Взгляд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('vzglyad.db')  # структура БД\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS news\n",
    "(year int, month int, day int, id_news int, time text, headline text, text text)\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def updbd(idnew, amount):\n",
    "\n",
    "    conn = sqlite3.connect('vzglyad.db')\n",
    "    cur = conn.cursor()\n",
    "    session = requests.session()\n",
    "    ua = UserAgent(verify_ssl=False)\n",
    "    \n",
    "    for link in tqdm(range(amount)):\n",
    "        url = f'https://vz.ru/news/2017/8/10/{idnew}.html'\n",
    "        response = session.get(url, headers={'User-Agent': ua.random})\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        \n",
    "        meta = soup.find('meta', {'property':'og:url'})\n",
    "        if meta:\n",
    "            meta = meta.get('content', []).replace('<br>', '<br> ')\n",
    "            if 'news' in meta:\n",
    "    \n",
    "                date = re.search(r'(\\d{4})\\/(\\d\\d?)\\/(\\d\\d?)\\/(\\d+?)\\.', meta)\n",
    "                year = date.group(1)\n",
    "                month = date.group(2)\n",
    "                day = date.group(3)\n",
    "                id_news = date.group(4)\n",
    "    \n",
    "                if soup.find('p', {'style':'float: left; margin: 0;  padding: 0'}):\n",
    "                    gtime = soup.find('p',{'style':'float: left; margin: 0;  padding: 0'})\n",
    "                    gtime = gtime.get_text()\n",
    "                    gti = gtime.split(',')[1].strip(' ')\n",
    "                elif soup.find('td', {'style':'padding:10px 0 10px 0;'}):\n",
    "                    alt_time = soup.find('td', {'style':'padding:10px 0 10px 0;'}).get_text()\n",
    "                    gti = re.search('\\d{2}:\\d{2}', alt_time).group()\n",
    "                else:\n",
    "                    gti = '-'\n",
    "                    print(idnew)\n",
    "    \n",
    "                headline = soup.find('meta', {'property':'og:title'}).get('content')\n",
    "                text = soup.find('div', {'class':'text newtext'}).get_text().replace('\\n', ' ').strip(' ')\n",
    "    \n",
    "                cur.execute(\n",
    "                    'INSERT INTO news VALUES (?, ?, ?, ?, ?, ?, ?)',\n",
    "                    (year, month, day, id_news, gti, headline, text))\n",
    "                conn.commit()\n",
    "            \n",
    "        idnew +=1\n",
    "       \n",
    "        time.sleep(random.uniform(1.3, 1.7))\n",
    "        \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "902183 - 900696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc8b321ee7a4801a923fd923d74d4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "updbd(900697, 1486) #902183"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
