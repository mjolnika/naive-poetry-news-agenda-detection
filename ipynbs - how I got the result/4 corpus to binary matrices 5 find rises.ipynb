{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from statistics import mean\n",
    "import datetime, time\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_stop = ['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'оно', 'когда-то', 'так',\n",
    "           'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'внутри', \n",
    "           'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли',\n",
    "           'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь',\n",
    "           'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы',\n",
    "           'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж',\n",
    "           'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'почти', 'мой',\n",
    "           'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'об',\n",
    "           'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много',\n",
    "           'разве', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя',\n",
    "           'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между', 'каждый', 'пусть', 'наш', 'один', 'лишь', 'твой',\n",
    "           'это', 'свой', 'весь',\n",
    "          'как-то', 'кто-то', 'любой', 'просто', 'самый', 'ваш', 'столь', 'из-за', 'который', 'что-нибудь',]\n",
    "\n",
    "\n",
    "ru_stop = ru_stop + list('бгдеёзйлмнпртфхцчшщьъыэю') #ивясакуож"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. news to zeroes\n",
    "### 2. poems to zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_to_zeroes(f, year, unidict, bidict): #, month\n",
    "    \n",
    "    file = open(f, \"r\", encoding='utf-8')\n",
    "    i = 0 \n",
    "    corpus = []\n",
    "    yearlength = int(re.search('(\\d+) ', str(datetime.date(year + 1, 1, 1) - datetime.date(year, 1, 1))).group(0))\n",
    "    print (\"Reading file \", f)\n",
    "    for line in file:\n",
    "        i += 1\n",
    "        year, mon, day, text = line.split('\\t')\n",
    "        date = datetime.date(year=int(year), month=int(mon), day=int(day))\n",
    "        tokens = text.strip(' \\n').split(' ')\n",
    "        tokens = [token for token in tokens if token not in ru_stop]\n",
    "        \n",
    "        for token in tokens:\n",
    "            if len(unidict[token]) < 1:\n",
    "                unidict[token] = [0 for i in range(yearlength)]\n",
    "            \n",
    "            if date != datetime.date(int(year), 1, 1):\n",
    "                position = int(re.search('(\\d+) ', str(date - datetime.date(int(year), 1, 1))).group(0))\n",
    "            else:\n",
    "                position = 0\n",
    "            unidict[token][position] = 1\n",
    "                    \n",
    "        for num, token in enumerate(tokens[1:]):\n",
    "            bigram = ' '.join([tokens[num-1], tokens[num]])\n",
    "            if len(bidict[bigram]) == 0:\n",
    "                bidict[bigram] = [0 for i in range(yearlength)]\n",
    "            if date != datetime.date(int(year), 1, 1):\n",
    "                position = int(re.search('(\\d+) ', str(date - datetime.date(int(year), 1, 1))).group(0))\n",
    "            else:\n",
    "                position = 0\n",
    "            bidict[bigram][position] = 1\n",
    "                    \n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            sys.stderr.write(\"Reading sentence \" + str(i) + \"\\n\") # just a status message: str(i) turns the integer i into a string, so that we can concatenate it\n",
    "      \n",
    "    return unidict, bidict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  F:\\c21\\save\\2008vz.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading sentence 10000\n",
      "Reading sentence 20000\n",
      "Reading sentence 30000\n",
      "Reading sentence 40000\n",
      "Reading sentence 50000\n",
      "Reading sentence 60000\n"
     ]
    }
   ],
   "source": [
    "year = 2008\n",
    "news = [f'{year}vz.tsv', f'{year}lenta.tsv']\n",
    "links = [os.path.join(r'F:\\c21\\save', file) for file in news]\n",
    "\n",
    "# zeroes\n",
    "news_uz = defaultdict(list)\n",
    "news_bz = defaultdict(list)\n",
    "\n",
    "start = time.time()\n",
    "for file in links:\n",
    "    news_uz, news_bz = dates_to_zeroes(file, int(year), news_uz, news_bz)\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(end - start) #prev 185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poems_to_zeroes(f, year, unidict, bidict, poemdict, poembidict): #, month\n",
    "    \n",
    "    file = open(f, \"r\", encoding='utf-8')\n",
    "    i = 0 \n",
    "    corpus = []\n",
    "    yearlength = int(re.search('(\\d+) ', str(datetime.date(year + 1, 1, 1) - datetime.date(year, 1, 1))).group(0))\n",
    "    print (\"Reading file \", f)\n",
    "    for line in file:\n",
    "        i += 1\n",
    "        year, mon, day, text = line.split('\\t')\n",
    "        date = datetime.date(year=int(year), month=int(mon), day=int(day))\n",
    "        tokens = text.strip(' \\n').split(' ')\n",
    "        tokens = [token for token in tokens if token not in ru_stop]\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token in unidict:\n",
    "                if len(poemdict[token]) < 1:\n",
    "                    poemdict[token] = [0 for i in range(yearlength)]\n",
    "                \n",
    "                if date != datetime.date(int(year), 1, 1):\n",
    "                    position = int(re.search('(\\d+) ', str(date - datetime.date(int(year), 1, 1))).group(0))\n",
    "                else:\n",
    "                    position = 0\n",
    "                poemdict[token][position] = 1\n",
    "            else:\n",
    "                pass\n",
    "                    \n",
    "        for num, token in enumerate(tokens[1:]):\n",
    "            bigram = ' '.join([tokens[num-1], tokens[num]])\n",
    "            if bigram in bidict:\n",
    "                if len(poembidict[bigram]) == 0:\n",
    "                    poembidict[bigram] = [0 for i in range(yearlength)]\n",
    "                if date != datetime.date(int(year), 1, 1):\n",
    "                    position = int(re.search('(\\d+) ', str(date - datetime.date(int(year), 1, 1))).group(0))\n",
    "                else:\n",
    "                    position = 0\n",
    "                poembidict[bigram][position] = 1\n",
    "            else:\n",
    "                pass\n",
    "                    \n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            sys.stderr.write(\"Reading sentence \" + str(i) + \"\\n\") # just a status message: str(i) turns the integer i into a string, so that we can concatenate it\n",
    "      \n",
    "    return poemdict, poembidict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poems = [\n",
    "f'mystem-{year}-01.tsv',\n",
    "f'mystem-{year}-02.tsv',\n",
    "f'mystem-{year}-03.tsv',\n",
    "f'mystem-{year}-04.tsv',\n",
    "f'mystem-{year}-05.tsv',\n",
    "f'mystem-{year}-06.tsv',\n",
    "f'mystem-{year}-07.tsv',\n",
    "f'mystem-{year}-08.tsv',\n",
    "f'mystem-{year}-09.tsv',\n",
    "f'mystem-{year}-10.tsv',\n",
    "f'mystem-{year}-11.tsv',\n",
    "f'mystem-{year}-12.tsv'\n",
    "]\n",
    "p_links = [os.path.join(r'F:\\c21\\poems_lemmatized', file) for file in poems]\n",
    "\n",
    "poems_uz = defaultdict(list)\n",
    "poems_bz = defaultdict(list)\n",
    "\n",
    "start = time.time()\n",
    "for file in p_links:\n",
    "    poems_uz, poems_bz = poems_to_zeroes(file, int(year), news_uz, news_bz, poems_uz, poems_bz)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/2 to .5 dump dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8910e47fb046b1bee9368c9b89e323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4350552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8633e28e689457d891389d71f7a5d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f'news-u{year}.json', 'w', encoding='utf-8') as t:\n",
    "    t.write('{\\n')\n",
    "    iswritten = 0\n",
    "    for key, value in news_uz.items():\n",
    "        if sum(value)>1:\n",
    "            if iswritten == 1:\n",
    "                t.write(',\\n')\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "            else:\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "                iswritten = 1\n",
    "    t.write('\\n}\\n')\n",
    "\n",
    "with open(f'news-b{year}.json', 'w', encoding='utf-8') as t:\n",
    "    t.write('{\\n')\n",
    "    iswritten = 0\n",
    "    for key, value in tqdm(news_bz.items()):\n",
    "        if sum(value)>1:\n",
    "            if iswritten == 1:\n",
    "                t.write(',\\n')\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "            else:\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "                iswritten = 1\n",
    "    t.write('\\n}\\n')\n",
    "\n",
    "with open(f'poems-u{year}.json', 'w', encoding='utf-8') as t:\n",
    "    t.write('{\\n')\n",
    "    iswritten = 0\n",
    "    for key, value in poems_uz.items():\n",
    "        if sum(value)>1:\n",
    "            if iswritten == 1:\n",
    "                    t.write(',\\n')\n",
    "                    t.write(f'\"{key}\":{value}')\n",
    "            else:\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "                iswritten = 1\n",
    "    t.write('\\n}\\n')\n",
    "\n",
    "with open(f'poems-b{year}.json', 'w', encoding='utf-8') as t:\n",
    "    t.write('{\\n')\n",
    "    iswritten = 0\n",
    "    for key, value in tqdm(poems_bz.items()):\n",
    "        if sum(value)>1:\n",
    "            if iswritten == 1:\n",
    "                t.write(',\\n')\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "            else:\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "                iswritten = 1\n",
    "    t.write('\\n}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a925071f515d41df95fe128590a69e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\":[0, 1, 5],\n",
      "\n",
      "\"90\":[0, 1, 1],\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ddict = {1: [0,1,5], 90:[0,1,1], 45:[0,1,0]}\n",
    "with open(f't.json', 'w', encoding='utf-8') as t:\n",
    "    t.write('{\\n')\n",
    "    length = 0\n",
    "    iswritten = 0\n",
    "    for key, value in tqdm(ddict.items()):\n",
    "        if sum(value)>1:\n",
    "            if iswritten == 1:\n",
    "                t.write(',\\n')\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "            else:\n",
    "                t.write(f'\"{key}\":{value}')\n",
    "                iswritten = 1\n",
    "    t.write('\\n')\n",
    "    t.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. split dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_year(yeardict, lag=10):\n",
    "    splitted_dict = {}\n",
    "    yearlength = len(next(iter(yeardict.values())))\n",
    "    amount = yearlength//lag\n",
    "    if yearlength%lag >0:\n",
    "        amount += 1\n",
    "    k = amount\n",
    "    n = yearlength\n",
    "    for token in tqdm(yeardict):\n",
    "        chunks = []\n",
    "        for i in range(k):\n",
    "            chunks.append(yeardict[token][i*lag : (i+1)*lag])\n",
    "        splitted_dict[token] = chunks\n",
    "    return splitted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4867802a4e46708e61fb6554579f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188918 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_news_u = split_year(news_uz)\n",
    "del news_uz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab3033104df477e8cd38e9d2a99ccfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_poems_u = split_year(poems_uz)\n",
    "del poems_uz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a82a51ac7a6438fac22aa7bbada0e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1394558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_news_b = split_year(news_bz)\n",
    "del news_bz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2b0427c5384b2b805f8672078e897e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/364207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_poems_b = split_year(poems_bz)\n",
    "del poems_bz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del split_news_u\n",
    "#del split_poems_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. find rises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rise(occurences, ma_days = 3, difference = 2):\n",
    "    mas = []\n",
    "    rises = set()\n",
    "    for occ_num, occ in enumerate(occurences):\n",
    "        ma = []\n",
    "        for i in range(ma_days):\n",
    "            index = occ_num -i\n",
    "            if index >= 0:\n",
    "                ma.append(sum(occurences[index]))\n",
    "        #print(occ_num, ma, sum(ma)/len(ma))\n",
    "        ma = sum(ma)/len(ma)\n",
    "        if len(mas) > 1 and sum(occurences[occ_num]) > mas[-1] + difference:  # вот тут вопрос как сделать\n",
    "            rises.add(occ_num)\n",
    "        mas.append(ma)\n",
    "    return rises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'rises_u{year}-3.tsv', 'w', encoding='utf-8') as f:\n",
    "    with open(f'rises_u_reverse{year}-3.tsv', 'w', encoding='utf-8') as r:\n",
    "        for token in split_news_u:\n",
    "            if token in split_poems_u:\n",
    "                news = find_rise(split_news_u[token], 3, 3)\n",
    "                poems = find_rise(split_poems_u[token], 3, 3)\n",
    "                check = poems and news\n",
    "                check2 = news and len(poems) == 0\n",
    "                if check:\n",
    "                    checked = '\\t'.join([(datetime.date(int(year), 1, 1) + datetime.timedelta(it*10)).strftime(\"%Y-%m-%d\") for it in sorted(check)])\n",
    "                    strng = f'{token}\\t{checked}\\n'\n",
    "                    f.write(strng)\n",
    "                if check2:\n",
    "                    checked = '\\t'.join([(datetime.date(int(year), 1, 1) + datetime.timedelta(it*10)).strftime(\"%Y-%m-%d\") for it in sorted(news)])\n",
    "                    strng = f'{token}\\t{checked}\\n'\n",
    "                    r.write(strng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'rises_b{year}-3.tsv', 'w', encoding='utf-8') as f:\n",
    "    with open(f'rises_b_reverse{year}-3.tsv', 'w', encoding='utf-8') as r:\n",
    "        for token in split_news_b:\n",
    "            if token in split_poems_b:\n",
    "                news = find_rise(split_news_b[token], 3, 3)\n",
    "                poems = find_rise(split_poems_b[token], 3, 3)\n",
    "                check = poems and news\n",
    "                check2 = news and len(poems) == 0\n",
    "                if check:\n",
    "                    checked = '\\t'.join([(datetime.date(int(year), 1, 1) + datetime.timedelta(it*10)).strftime(\"%Y-%m-%d\") for it in sorted(check)])\n",
    "                    strng = f'{token}\\t{checked}\\n'\n",
    "                    f.write(strng)\n",
    "                if check2:\n",
    "                    checked = '\\t'.join([(datetime.date(int(year), 1, 1) + datetime.timedelta(it*10)).strftime(\"%Y-%m-%d\") for it in sorted(news)])\n",
    "                    strng = f'{token}\\t{checked}\\n'\n",
    "                    r.write(strng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 rises not presented in poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'rises_u{year}NOPOEM.tsv', 'w', encoding='utf-8') as f:\n",
    "    for token in split_news_u:\n",
    "        if token not in split_poems_u:\n",
    "            news = find_rise(split_news_u[token])\n",
    "            if news:\n",
    "                checked = '\\t'.join([(datetime.date(int(year), 1, 1) + datetime.timedelta(it*10)).strftime(\"%Y-%m-%d\") for it in sorted(news)])\n",
    "                strng = f'{token}\\t{checked}\\n'\n",
    "                f.write(strng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'rises_b{year}NOPOEM.tsv', 'w', encoding='utf-8') as f:\n",
    "    for token in split_news_b:\n",
    "        if token not in split_poems_b:\n",
    "            news = find_rise(split_news_b[token])\n",
    "            if news:\n",
    "                checked = '\\t'.join([(datetime.date(int(year), 1, 1) + datetime.timedelta(it*10)).strftime(\"%Y-%m-%d\") for it in sorted(news)])\n",
    "                strng = f'{token}\\t{checked}\\n'\n",
    "                f.write(strng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (2.5.) read & write preprocessed (zeroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'poems-u{year}.json', encoding ='utf8') as json_file: \n",
    "    poems_uz = json.load(json_file) \n",
    "    \n",
    "with open(f'news-u{year}.json', encoding ='utf8') as json_file: \n",
    "    news_uz = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'news-b{year}.json', encoding ='utf8') as json_file: \n",
    "    news_bz = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'poems-b{year}.json', encoding ='utf8') as json_file: \n",
    "    poems_bz = json.load(json_file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
